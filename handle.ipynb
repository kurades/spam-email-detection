{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, f1_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0    label_num\n",
      "count  5171.000000  5171.000000\n",
      "mean   2585.000000     0.289886\n",
      "std    1492.883452     0.453753\n",
      "min       0.000000     0.000000\n",
      "25%    1292.500000     0.000000\n",
      "50%    2585.000000     0.000000\n",
      "75%    3877.500000     1.000000\n",
      "max    5170.000000     1.000000\n"
     ]
    }
   ],
   "source": [
    "#load dataset\n",
    "dataframe = pd.read_csv('spam_ham_dataset.csv')\n",
    "print(dataframe.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data\n",
    "x = dataframe[\"text\"]\n",
    "y = dataframe[\"label\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features\n",
    "# cv = CountVectorizer()\n",
    "\n",
    "# cv.fit(x_train)\n",
    "# features = cv.transform(x_train)\n",
    "\n",
    "# tuned_parameters = {'kernel': ['rbf', 'linear'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]}\n",
    "# model = GridSearchCV(svm.SVC(), tuned_parameters)\n",
    "# model2 = MultinomialNB()\n",
    "# model3 = RandomForestClassifier()\n",
    "# model4 = LogisticRegression()\n",
    "\n",
    "# model.fit(features, y_train)\n",
    "# model2.fit(features, y_train)\n",
    "# model3.fit(features, y_train)\n",
    "# model4.fit(features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_file = \"cv.pkl\"\n",
    "svm_file = 'svm_model.pkl'\n",
    "nb_file = 'nb_model.pkl'\n",
    "rf_file = 'rf_model.pkl'\n",
    "lr_file = 'lr_model.pkl'\n",
    "\n",
    "# #dump models into pickle files for quick access pickle.dump(cv, open(cv_file, \"wb\"))\n",
    "# pickle.dump(cv, open(cv_file, 'wb'))\n",
    "# print('cv has loaded')\n",
    "\n",
    "# pickle.dump(model, open(svm_file, 'wb'))\n",
    "# pickle.dump(model2, open(nb_file, 'wb'))\n",
    "# pickle.dump(model3, open(rf_file, 'wb'))\n",
    "# pickle.dump(model4, open(lr_file, 'wb'))\n",
    "# print( 'models are loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = pickle.load(open(cv_file, 'rb'))\n",
    "loaded_svm_model = pickle.load(open(svm_file, 'rb'))\n",
    "loaded_nb_model = pickle.load(open(nb_file, 'rb'))\n",
    "loaded_rf_model = pickle.load(open(rf_file, 'rb'))\n",
    "loaded_lr_model = pickle.load(open(lr_file, 'rb'))\n",
    "prediction_set = x_test.tolist()\n",
    "svm_predicted_set = []\n",
    "nb_predicted_set = []\n",
    "rf_predicted_set = []\n",
    "lr_predicted_set = []\n",
    "\n",
    "for row in prediction_set:\n",
    "  row = [row]\n",
    "  transform = cv.transform(row)\n",
    "  svm_result = loaded_svm_model.predict(transform)\n",
    "  nb_result = loaded_nb_model.predict(transform)\n",
    "  rf_result = loaded_rf_model.predict(transform)\n",
    "  lr_result = loaded_lr_model.predict(transform)\n",
    "  svm_predicted_set.append (svm_result)\n",
    "  nb_predicted_set.append(nb_result)\n",
    "  rf_predicted_set.append(rf_result)\n",
    "  lr_predicted_set.append(lr_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "confusion matrix for SVM: [[ 435   26]\n",
      " [  34 1212]]\n",
      "accuracy of svm = 0.9648506151142355\n",
      "precision of svm for ham and spam = [0.97899838 0.92750533]\n",
      "recall of svm for ham and spam = [0.97271268 0.94360087]\n",
      "sens and spec for svm model = 0.9436008676789588 0.9727126805778491\n",
      "f1 score for svm = [0.97584541 0.93548387]\n",
      "***********************\n",
      "Naive Bayes\n",
      "confusion matrix for Naive Bayes: [[ 439   22]\n",
      " [  18 1228]]\n",
      "accuracy of naive bayes = 0.9765670767428236\n",
      "precision of naive bayes for ham and spam = [0.9824     0.96061269]\n",
      "recall of naive bayes for ham and spam = [0.98555377 0.95227766]\n",
      "sens and spec for naive bayes model = 0.9522776572668112 0.985553772070626\n",
      "f1 score for naive bayes = [0.98397436 0.95642702]\n",
      "***********************\n",
      "Random Forest\n",
      "confusion matrix for Random Forest: [[ 427   34]\n",
      " [  22 1224]]\n",
      "accuracy of Random Forest = 0.9671939074399531\n",
      "precision of Random Forest for ham and spam = [0.97297297 0.95100223]\n",
      "recall of Random Forest for ham and spam = [0.9823435  0.92624729]\n",
      "sens and spec for Random Forest model = 0.9262472885032538 0.9823434991974318\n",
      "f1 score for Random Forest = [0.97763578 0.93846154]\n",
      "***********************\n",
      "Logistic Regression\n",
      "confusion matrix for Logistic Regression: [[ 448   13]\n",
      " [  28 1218]]\n",
      "accuracy of Logistic Regression = 0.9759812536613942\n",
      "precision of Logistic Regression for ham and spam = [0.98943948 0.94117647]\n",
      "recall of Logistic Regression for ham and spam = [0.97752809 0.97180043]\n",
      "sens and spec for Logistic Regression model = 0.9718004338394793 0.9775280898876404\n",
      "f1 score for Logistic Regression = [0.98344772 0.95624333]\n",
      "***********************\n"
     ]
    }
   ],
   "source": [
    "svm__confusion_matrix = confusion_matrix(y_test, svm_predicted_set, labels=['spam', 'ham'])\n",
    "svm_sensitivity = svm__confusion_matrix[0,0]/(svm__confusion_matrix[0,0]+svm__confusion_matrix[0,1])\n",
    "svm_specificity = svm__confusion_matrix[1,1]/(svm__confusion_matrix[1,0]+svm__confusion_matrix[1,1])\n",
    "\n",
    "nb_confusion_matrix = confusion_matrix(y_test, nb_predicted_set, labels=['spam', 'ham'])\n",
    "nb_sensitivity = nb_confusion_matrix[0,0]/(nb_confusion_matrix[0,0]+nb_confusion_matrix[0,1])\n",
    "nb_specificity = nb_confusion_matrix[1,1]/(nb_confusion_matrix[1,0]+nb_confusion_matrix[1,1])\n",
    "\n",
    "rf_confusion_matrix = confusion_matrix(y_test, rf_predicted_set, labels=['spam', 'ham'])\n",
    "rf_sensitivity = rf_confusion_matrix[0,0]/(rf_confusion_matrix[0,0]+rf_confusion_matrix[0,1])\n",
    "rf_specificity = rf_confusion_matrix[1,1]/(rf_confusion_matrix[1,0]+rf_confusion_matrix[1,1])\n",
    "\n",
    "lr_confusion_matrix = confusion_matrix(y_test, lr_predicted_set, labels=['spam', 'ham'])\n",
    "lr_sensitivity = lr_confusion_matrix[0,0]/(lr_confusion_matrix[0,0]+lr_confusion_matrix[0,1])\n",
    "lr_specificity = lr_confusion_matrix[1,1]/(lr_confusion_matrix[1,0]+lr_confusion_matrix[1,1])\n",
    "\n",
    "print('SVM')\n",
    "print('confusion matrix for SVM: '+ str(svm__confusion_matrix))\n",
    "print('accuracy of svm = ' + str(loaded_svm_model.score(cv.transform(x_test), y_test)))\n",
    "print('precision of svm for ham and spam = ' + str(precision_score(y_test, svm_predicted_set, average=None)))\n",
    "print('recall of svm for ham and spam = '+ str(recall_score(y_test, svm_predicted_set, average=None)))\n",
    "print('sens and spec for svm model = ' + str(svm_sensitivity) + ' ' + str(svm_specificity))\n",
    "print('f1 score for svm = ' + str(f1_score(y_test, svm_predicted_set, average=None)))\n",
    "print('***********************')\n",
    "\n",
    "print('Naive Bayes')\n",
    "print('confusion matrix for Naive Bayes: '+ str(nb_confusion_matrix))\n",
    "print('accuracy of naive bayes = ' + str(loaded_nb_model.score(cv.transform(x_test), y_test)))\n",
    "print('precision of naive bayes for ham and spam = ' + str(precision_score(y_test, nb_predicted_set, average=None)))\n",
    "print('recall of naive bayes for ham and spam = '+ str(recall_score(y_test, nb_predicted_set, average=None)))\n",
    "print('sens and spec for naive bayes model = ' + str(nb_sensitivity) + ' ' + str(nb_specificity))\n",
    "print('f1 score for naive bayes = ' + str(f1_score(y_test, nb_predicted_set, average=None)))\n",
    "print('***********************')\n",
    "\n",
    "print('Random Forest')\n",
    "print('confusion matrix for Random Forest: '+ str(rf_confusion_matrix))\n",
    "print('accuracy of Random Forest = ' + str(loaded_rf_model.score(cv.transform(x_test), y_test)))\n",
    "print('precision of Random Forest for ham and spam = ' + str(precision_score(y_test, rf_predicted_set, average=None)))\n",
    "print('recall of Random Forest for ham and spam = '+ str(recall_score(y_test, rf_predicted_set, average=None)))\n",
    "print('sens and spec for Random Forest model = ' + str(rf_sensitivity) + ' ' + str(rf_specificity))\n",
    "print('f1 score for Random Forest = ' + str(f1_score(y_test, rf_predicted_set, average=None)))\n",
    "print('***********************')\n",
    "\n",
    "print('Logistic Regression')\n",
    "print('confusion matrix for Logistic Regression: '+ str(lr_confusion_matrix))\n",
    "print('accuracy of Logistic Regression = ' + str(loaded_lr_model.score(cv.transform(x_test), y_test)))\n",
    "print('precision of Logistic Regression for ham and spam = ' + str(precision_score(y_test, lr_predicted_set, average=None)))\n",
    "print('recall of Logistic Regression for ham and spam = '+ str(recall_score(y_test, lr_predicted_set, average=None)))\n",
    "print('sens and spec for Logistic Regression model = ' + str(lr_sensitivity) + ' ' + str(lr_specificity))\n",
    "print('f1 score for Logistic Regression = ' + str(f1_score(y_test, lr_predicted_set, average=None)))\n",
    "print('***********************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month going teach thing two may signals end school year upon us procrastinate papers assignments grading making glitch app thatteaches thing whether tutorial guides fan art favorite fun fact month building apps make others say today learned head glitchcomjams right learn jams participate see wha tthe community made past jams well inspiration month join friday 2pm eastern glitch jams live ill showing last months submissions looking inspiration month happy jamming cant wait see create see glitchcomjams jenn director community\n",
      "SVM: ['spam']\n",
      "Naive Bayes: ['spam']\n",
      "Random Forest: ['ham']\n",
      "Logistic Regression: ['spam']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# Read the HTML file\n",
    "with open('test.html', 'r') as file:\n",
    "  html_content = file.read()\n",
    "\n",
    "# Remove HTML tags\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "text = soup.get_text()\n",
    "\n",
    "# Remove punctuation and convert to lowercase\n",
    "text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "\n",
    "# Remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "\n",
    "# Print the filtered text\n",
    "print(filtered_text)\n",
    "transform = cv.transform([filtered_text])\n",
    "result1 = loaded_svm_model.predict(transform)\n",
    "result2 = loaded_nb_model.predict(transform)\n",
    "result3 = loaded_rf_model.predict(transform)\n",
    "result4 = loaded_lr_model.predict(transform)\n",
    "print('SVM: ' + str(result1))\n",
    "print('Naive Bayes: ' + str(result2))\n",
    "print('Random Forest: ' + str(result3))\n",
    "print('Logistic Regression: ' + str(result4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
